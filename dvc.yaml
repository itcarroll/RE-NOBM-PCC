stages:
  oasim:
    # generate corresponding lwn files for each nobm file
    # TODO study /usr/bin/time -v and improve cluster efficiency
    cmd:
      sbatch
        --job-name=oasim
        --array=0-17%6
        --cpus-per-task=128
        --exclusive
        --wrap="python -m re_nobm_pcc.phy2lwn"
        &&
      mkdir data/oasim
    deps:
    - data/nobm
    - data/oasim_param
    - re_nobm_pcc/phy2lwn.py
    - oasim
    outs:
    - data/oasim
    frozen: true
  preprocess:
    # prepare the features and labels for model training
    # on gpu for tf analysis?
    cmd: srun --gres=gpu:1 python -m re_nobm_pcc.preprocess
    deps:
    - data/nobm
    - re_nobm_pcc/kit.py
    - re_nobm_pcc/preprocess.py
    outs:
    - data/train
    - data/validate
    - data/test
    - data/sample.nc
  preview:
    # generate report on the features and labels
    cmd: jupyter nbconvert
      --execute
      --no-input
      --to html
      --output docs/preview.html
      notebooks/preview.ipynb
    deps:
    - data/nobm
    - re_nobm_pcc/kit.py
    - re_nobm_pcc/preprocess.py
    - notebooks/preview.ipynb
    outs:
    - notebooks/preview.html
    frozen: true
  learn:
    # train the model
    cmd: srun --gres=gpu:1 python -m re_nobm_pcc.learn
    deps:
    - data/train
    - data/validate
    - data/test
    - re_nobm_pcc/kit.py
    - re_nobm_pcc/learn.py
    outs:
    - data/model
    - data/fit.npz
    metrics:
    - data/metrics.json:
        cache: false
  evaluate:
    # generate report on model performance
    cmd: jupyter nbconvert
      --execute
      --no-input
      --to html
      --output evaluate.html
      notebooks/evaluate.ipynb
    deps:
    - notebooks/evaluate.ipynb
    - data/model
    - data/fit.npz
    - data/metrics.json
    outs:
    - notebooks/evaluate.html
