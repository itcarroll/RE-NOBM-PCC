{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from importlib import reload\n",
    "\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import xarray as xr\n",
    "\n",
    "from re_nobm_pcc import DATA_DIR, TAXA\n",
    "from re_nobm_pcc import learn, viz\n",
    "\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = DATA_DIR / '../.dvc/tmp/exps/standalone/tmpq_rtdiex/data'\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = reload(learn)\n",
    "network = learn.make_network(6)\n",
    "network.load_weights(DATA_DIR / 'fit' / 'epoch-210')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = DATA_DIR/'../.dvc/tmp/exps/standalone/tmpq_rtdiex/data'\n",
    "network = tf.keras.models.load_model(DATA_DIR/'network', compile=False)\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss by Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = xr.Dataset({\n",
    "    k: ('epoch', v) for k, v in np.load(DATA_DIR / 'fit.npz').items()\n",
    "})\n",
    "offset = 1 - min(*tuple(v.item() for k, v in fit.min().items()))\n",
    "viz.loss(fit, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.load_weights(DATA_DIR / 'fit' / 'epoch-90')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_index = pd.Series(['mean'] + [str(i+1) for i in range(5)], index=TAXA)\n",
    "with (DATA_DIR/'metrics.json').open() as stream:\n",
    "    metrics = json.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = (\n",
    "    pd.DataFrame.from_dict(\n",
    "        {tuple(k.split('_'))[-2:]: [v] for k, v in metrics.items()},\n",
    "        orient='columns',\n",
    "    )\n",
    "    .stack(level=0).droplevel(0)\n",
    ")\n",
    "columns = ['ME', 'MAE', 'RMSE', 'R2']\n",
    "table = pd.concat((pd.DataFrame(columns=columns), table))\n",
    "table = table.loc[fix_index]\n",
    "table.index = fix_index.index\n",
    "table[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: True vs. Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.builder('rrs_day_tfds', data_dir=DATA_DIR)\n",
    "test = dataset.as_dataset(split='split[9%:10%]', as_supervised=True)\n",
    "test = test.batch(2 ** 16)\n",
    "y_true = []\n",
    "y_mu = []\n",
    "y_sd = []\n",
    "y_sample = []\n",
    "for item in test:\n",
    "    y_true.append(item[1].numpy())\n",
    "    y_pred = network(item[0])\n",
    "    y_mu.append(y_pred.mean().numpy())\n",
    "    y_sd.append(y_pred.stddev().numpy())\n",
    "    y_sample.append(y_pred.sample().numpy())\n",
    "y_true = np.concatenate(y_true)\n",
    "y_mu = np.concatenate(y_mu)\n",
    "y_sd = np.concatenate(y_sd)\n",
    "y_sample = np.concatenate(y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXCV = 1\n",
    "ds = xr.Dataset({\n",
    "    'y_true': (('pxl', 'phy'), y_true),\n",
    "    'y_pred': (('pxl', 'phy'), y_sample),\n",
    "    'mask_high_cv': (('pxl', 'phy'), (y_sd / (y_mu + 1e-32)) < MAXCV),\n",
    "    'phy': ('phy', list(TAXA)),\n",
    "})\n",
    "ds['mask_high_cv'].sum('pxl') / ds.sizes['pxl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "phy = ds.sel({'phy': TAXA[i]})\n",
    "phy = phy[['y_true', 'y_pred']].where(phy['mask_high_cv'])\n",
    "(\n",
    "    hv.HexTiles(data=(phy['y_pred'], phy['y_true']), kdims=['prediction', 'truth'])\n",
    "    .options(\n",
    "        title=TAXA[i],\n",
    "        logz=True,\n",
    "        tools=['hover'],\n",
    "        # padding=0.001,\n",
    "        aspect=1,\n",
    "        fontscale=1.4,\n",
    "        colorbar=True,\n",
    "    )\n",
    "    * hv.Slope(1, 0).options(color='red', line_width=1.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.hexbin(np.log10(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
