{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from importlib import reload\n",
    "\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from re_nobm_pcc import DATA_DIR, TAXA\n",
    "from re_nobm_pcc import viz\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = reload(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = tf.keras.models.load_model(\n",
    "    DATA_DIR/'network',\n",
    "    compile=False,\n",
    ")\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss by Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = xr.Dataset({\n",
    "    k: ('epoch', v) for k, v in np.load(DATA_DIR / 'fit.npz').items()\n",
    "})\n",
    "viz.loss(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (DATA_DIR/'metrics.json').open() as stream:\n",
    "    metrics = json.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Test loss: {metrics['loss']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = (\n",
    "    pd.DataFrame.from_dict(\n",
    "        {tuple(k.split('_'))[-2:]: [v] for k, v in metrics.items()},\n",
    "        orient='columns',\n",
    "    )\n",
    "    .stack(level=0).droplevel(0)\n",
    ")\n",
    "columns = ['loss', 'AUC', 'ME', 'MAE', 'RMSE', 'R2']\n",
    "table = pd.concat((pd.DataFrame(columns=columns), table))\n",
    "table[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: True vs. Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.load(str(DATA_DIR/'test'))\n",
    "test = test.batch(test.cardinality())\n",
    "_, y = next(test.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = {\n",
    "    model.outputs[i].node.layer.name: item\n",
    "    for i, item in enumerate(model.predict(test, verbose=0))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xr.Dataset(\n",
    "    {i: (('pxl',), y[f'abundance_{i}']) for i in TAXA}\n",
    ")\n",
    "if table['AUC'].any():\n",
    "    test = xr.merge(\n",
    "        (\n",
    "            xr.Dataset(\n",
    "                {f'{i}_presence_hat': (('pxl',), y_hat[f'presence_{i}'].flatten()) for i in TAXA}\n",
    "            ),\n",
    "            xr.Dataset(\n",
    "                {f'{i}_hat': (('pxl',), (\n",
    "                    (y_hat[f'abundance_{i}'][:, :1] * (y_hat[f'presence_{i}'] > 0)).flatten()\n",
    "                )) for i in TAXA}\n",
    "            ),\n",
    "            test\n",
    "        )\n",
    "    )\n",
    "    roc(test)\n",
    "else:\n",
    "    test = xr.merge(\n",
    "        (\n",
    "            xr.Dataset(\n",
    "                {f'{i}_hat': (('pxl',), y_hat[f'abundance_{i}'][:, :1].flatten()) for i in TAXA}\n",
    "            ),\n",
    "            test\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexbin(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexbin(np.log10(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
