{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chl-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load directly fom netcdf\n",
    "- fit a linear regressin with least square\n",
    "- fit a regression with variance estimated too\n",
    "- make it bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import warnings\n",
    "import datetime as dt\n",
    "\n",
    "from IPython.display import Markdown\n",
    "from scipy.stats import zscore\n",
    "import holoviews as hv\n",
    "import hvplot.xarray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import param as p\n",
    "import xarray as xr\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "# import tensorflow_probability as tfp\n",
    "\n",
    "# from re_nobm_pcc import preprocess\n",
    "from re_nobm_pcc import DATADIR, TAXA, WAVELENGTH\n",
    "from re_nobm_pcc import kit\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", category=FutureWarning)\n",
    "hv.opts.defaults(\n",
    "    hv.opts.Curve(active_tools=[]),\n",
    "    hv.opts.Image(active_tools=[]),\n",
    "    hv.opts.Scatter(active_tools=[]),\n",
    "    hv.opts.HexTiles(active_tools=[], tools=[\"hover\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_name = {\n",
    "    \"alk\": \"alkalinity\",\n",
    "    \"cdc\": \"colored dissolved carbon\",\n",
    "    \"chl\": \"chlorophytes\",\n",
    "    \"coc\": \"coccolithophores\",\n",
    "    \"cya\": \"cyanobacteria\",\n",
    "    \"dia\": \"diatoms\",\n",
    "    \"dic\": \"dissolved organic carbon\",\n",
    "    \"din\": \"dinoflagellate\",\n",
    "    \"doc\": \"dissolved organic carbon\",\n",
    "    \"dtc\": \"dissolved total carbon\",\n",
    "    \"fco\": \"carbon dioxide flux\",\n",
    "    \"h\": \"mixed layer depth\",\n",
    "    \"irn\": \"iron\",\n",
    "    \"pco\": \"carbon dioxide concentration\",\n",
    "    \"pha\": \"phaeocystis\",\n",
    "    \"pic\": \"particulate inorganic carbon\",\n",
    "    \"pp\": \"phytoplankton primary productivity\",\n",
    "    \"tpp\": \"total primary productivity\",\n",
    "    \"rnh\": \"ammonium\",\n",
    "    \"rno\": \"nitrate\",\n",
    "    \"s\": \"salinity\",\n",
    "    \"t\": \"temperature\",\n",
    "    \"tot\": \"total chlorophyl\",\n",
    "    \"zoo\": \"zooplankton\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chl-a OC4 Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OC4 (SeaWiFS) from https://oceancolor.gsfc.nasa.gov/atbd/chlor_a/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0.32814, -3.20725, 3.22969, -1.36769, -0.81739]\n",
    "blue = [443, 489, 510]\n",
    "green = 555\n",
    "\n",
    "dim = \"wavelength\"\n",
    "da = xr.DataArray(\n",
    "    np.arange(len(WAVELENGTH)),\n",
    "    coords={dim: ds[dim].loc[WAVELENGTH[0] : WAVELENGTH[-1]]},\n",
    ")\n",
    "blue = da.sel({dim: blue}, method=\"nearest\").values.tolist()\n",
    "green = da.sel({dim: green}, method=\"nearest\").values.item()\n",
    "\n",
    "a = tf.expand_dims(tf.constant(a), 1)\n",
    "blue, green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def log_blue_green_ratio(x, y):\n",
    "    return (\n",
    "        tf.expand_dims(\n",
    "            tf.experimental.numpy.log10(\n",
    "                tf.reduce_max(tf.gather(x, blue, axis=1), axis=1) / x[:, green]\n",
    "            ),\n",
    "            axis=1,\n",
    "        ),\n",
    "        tf.expand_dims(tf.experimental.numpy.log10(tf.reduce_sum(y, axis=1)), axis=1),\n",
    "    )\n",
    "\n",
    "\n",
    "batch_size = 2**10\n",
    "tfds_rrs_day = tfds.builder(\"rrs_day_tfds\", data_dir=DATA_DIR)\n",
    "train, test = tfds_rrs_day.as_dataset(\n",
    "    split=[\"split[:8%]\", \"split[9%:10%]\"], as_supervised=True\n",
    ")\n",
    "train_size = train.cardinality()\n",
    "test_size = test.cardinality()\n",
    "train = train.batch(batch_size).cache()\n",
    "test = test.batch(batch_size).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_x, log_y = test.map(log_blue_green_ratio).rebatch(test_size).get_single_element()\n",
    "log_y = log_y[:, 0].numpy()\n",
    "log_y_hat = (log_x ** tf.range(5, dtype=np.float32) @ a)[:, 0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = 1 - ((log_y - log_y_hat) ** 2).sum() / ((log_y - log_y.mean()) ** 2).sum()\n",
    "print(f\"R2: {R2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    hv.Scatter(\n",
    "        (log_y_hat[: 2**16], log_y[: 2**16]),\n",
    "        kdims=\"prediction\",\n",
    "        vdims=\"truth\",\n",
    "    )\n",
    "    + hv.HexTiles(\n",
    "        (log_y_hat, log_y),\n",
    "        kdims=[\"prediction\", \"truth\"],\n",
    "    ).opts(logz=True)\n",
    ") * hv.Slope(1, 0).opts(color=\"black\", line_width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Lambda(lambda x: x ** tf.range(1, 5, dtype=np.float32)),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "network.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = network.fit(\n",
    "    train.map(log_blue_green_ratio).shuffle(batch_size * 4),\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.layers[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_x, log_y = test.map(log_blue_green_ratio).rebatch(test_size).get_single_element()\n",
    "log_y_hat = network(log_x)[:, 0].numpy()\n",
    "log_y = log_y[:, 0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = 1 - ((log_y - log_y_hat) ** 2).sum() / ((log_y - log_y.mean()) ** 2).sum()\n",
    "print(f\"R2: {R2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    hv.Scatter(\n",
    "        (log_y_hat[: 2**16], log_y[: 2**16]),\n",
    "        kdims=\"prediction\",\n",
    "        vdims=\"truth\",\n",
    "    )\n",
    "    + hv.HexTiles(\n",
    "        (log_y_hat, log_y),\n",
    "        kdims=[\"prediction\", \"truth\"],\n",
    "    ).opts(logz=True)\n",
    ") * hv.Slope(1, 0).opts(color=\"black\", line_width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def four_wavelengths(x, y):\n",
    "    return (\n",
    "        tf.experimental.numpy.log10(\n",
    "            tf.concat(\n",
    "                (tf.gather(x, blue, axis=1), tf.gather(x, [green], axis=1)),\n",
    "                axis=1,\n",
    "            )\n",
    "        ),\n",
    "        tf.experimental.numpy.log10(tf.reduce_sum(y, axis=1)),\n",
    "    )\n",
    "\n",
    "\n",
    "network = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, \"relu\"),\n",
    "        tf.keras.layers.Dense(64, \"relu\"),\n",
    "        tf.keras.layers.Dense(64, \"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "network.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = network.fit(\n",
    "    train.map(four_wavelengths).shuffle(batch_size * 4),\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_x, log_y = test.map(four_wavelengths).rebatch(test_size).get_single_element()\n",
    "log_y_hat = network(log_x)[:, 0].numpy()\n",
    "log_y = log_y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = 1 - ((log_y - log_y_hat) ** 2).sum() / ((log_y - log_y.mean()) ** 2).sum()\n",
    "print(f\"R2: {R2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    hv.Scatter(\n",
    "        (log_y_hat[: 2**16], log_y[: 2**16]),\n",
    "        kdims=\"prediction\",\n",
    "        vdims=\"truth\",\n",
    "    )\n",
    "    + hv.HexTiles(\n",
    "        (log_y_hat, log_y),\n",
    "        kdims=[\"prediction\", \"truth\"],\n",
    "    ).opts(logz=True)\n",
    ") * hv.Slope(1, 0).opts(color=\"black\", line_width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlp, loc scale out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, \"relu\"),\n",
    "        tf.keras.layers.Dense(64, \"relu\"),\n",
    "        tf.keras.layers.Dense(64, \"relu\"),\n",
    "        tf.keras.layers.Dense(2),\n",
    "        tfp.layers.IndependentNormal(1),\n",
    "    ]\n",
    ")\n",
    "network.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=lambda y, model: tf.reduce_sum(-model.log_prob(y)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = network.fit(\n",
    "    train.map(four_wavelengths).shuffle(batch_size * 4),\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_x, log_y = test.map(four_wavelengths).rebatch(test_size).get_single_element()\n",
    "log_y_model = network(log_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = log_y_model.stddev() / tf.abs(log_y_model.mean()) < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_y_hat = tf.boolean_mask(log_y_model.sample(), idx).numpy()\n",
    "log_y = tf.boolean_mask(log_y, idx[:, 0]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = 1 - ((log_y - log_y_hat) ** 2).sum() / ((log_y - log_y.mean()) ** 2).sum()\n",
    "print(f\"R2: {R2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    hv.Scatter(\n",
    "        (log_y_hat[: 2**16], log_y[: 2**16]),\n",
    "        kdims=\"prediction\",\n",
    "        vdims=\"truth\",\n",
    "    )\n",
    "    + hv.HexTiles(\n",
    "        (log_y_hat, log_y),\n",
    "        kdims=[\"prediction\", \"truth\"],\n",
    "    ).opts(logz=True)\n",
    ") * hv.Slope(1, 0).opts(color=\"black\", line_width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE transform to standard normal and plot ecdf"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
