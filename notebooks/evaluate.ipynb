{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from importlib import reload\n",
    "\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import xarray as xr\n",
    "\n",
    "from re_nobm_pcc import DATA_DIR, TAXA\n",
    "from re_nobm_pcc import viz\n",
    "\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = DATA_DIR/'../.dvc/tmp/exps/standalone/tmpffedw8na/data'\n",
    "network = tf.keras.models.load_model(DATA_DIR/'network', compile=False)\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss by Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = xr.Dataset({\n",
    "    k: ('epoch', v) for k, v in np.load(DATA_DIR / 'fit.npz').items()\n",
    "})\n",
    "offset = 1 - min(*tuple(v.item() for k, v in fit.min().items()))\n",
    "viz.loss(fit, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.load_weights(DATA_DIR / 'fit' / 'epoch-90')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_index = pd.Series(['mean'] + [str(i+1) for i in range(5)], index=TAXA)\n",
    "with (DATA_DIR/'metrics.json').open() as stream:\n",
    "    metrics = json.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = (\n",
    "    pd.DataFrame.from_dict(\n",
    "        {tuple(k.split('_'))[-2:]: [v] for k, v in metrics.items()},\n",
    "        orient='columns',\n",
    "    )\n",
    "    .stack(level=0).droplevel(0)\n",
    ")\n",
    "columns = ['ME', 'MAE', 'RMSE', 'R2']\n",
    "table = pd.concat((pd.DataFrame(columns=columns), table))\n",
    "table = table.loc[fix_index]\n",
    "table.index = fix_index.index\n",
    "table[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: True vs. Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAKE = 8\n",
    "\n",
    "dataset = tfds.builder('rrs_day_tfds', data_dir=DATA_DIR)\n",
    "test = dataset.as_dataset(split='split[9%:10%]', as_supervised=True)\n",
    "test = test.batch(2 ** 12)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for item in test.take(TAKE):\n",
    "    y_true.append(item[1].numpy())\n",
    "    y_pred.append(network(item[0]).numpy()) # TODO hopefully .mean()\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "ds = xr.Dataset({\n",
    "    'y_true': (('pxl', 'phy'), y_true),\n",
    "    'y_pred': (('pxl', 'phy'), y_pred),\n",
    "    'phy': ('phy', list(TAXA)),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.hexbin(np.log10(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
